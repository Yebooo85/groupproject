{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quan = '../output_metric/Quantity_metrics.csv'\n",
    "quan = '../output_metric/AML.csv'\n",
    "quan_filter = '../output_metric/Quantity_metrics_filter.csv'\n",
    "\n",
    "qual = '../output_metric/Qualitative_metrics.csv'\n",
    "qual_filter = '../output_metric/Qualitative_metrics_filter.csv'\n",
    "\n",
    "merge = '../output_metric/metrics.csv'\n",
    "merge_filter = '../output_metric/metrics_filter.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been merged and saved as Merged_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取文件\n",
    "df_quan = pd.read_csv(quan)\n",
    "df_qual = pd.read_csv(qual)\n",
    "\n",
    "df_quan.columns = df_quan.columns.str.lower()\n",
    "df_qual.columns = df_qual.columns.str.lower()\n",
    "\n",
    "# 按行合并，自动处理列名不一致的情况\n",
    "merged_df = pd.concat([df_quan, df_qual], axis=0, ignore_index=True)\n",
    "\n",
    "# 保存合并后的文件\n",
    "merged_df.to_csv(merge, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Files have been merged and saved as Merged_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating metrics embeddings: 100%|██████████| 54/54 [00:19<00:00,  2.70it/s]\n",
      "Calculating target label embeddings: 100%|██████████| 156/156 [00:57<00:00,  2.71it/s]\n",
      "Calculating similarities: 100%|██████████| 54/54 [00:00<00:00, 482.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering is complete.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 加载BERT模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 定义函数获取BERT嵌入并显示进度条\n",
    "def get_bert_embeddings_with_progress(text_list, description=\"Calculating embeddings\"):\n",
    "    embeddings = []\n",
    "    for text in tqdm(text_list, desc=description):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=128, padding='max_length')\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings\n",
    "\n",
    "# 加载CSV文件\n",
    "data_source = merge  # 数据源路径\n",
    "data = pd.read_csv(data_source)\n",
    "\n",
    "# 从CSV提取 `metric`、`value` 和 `unit`\n",
    "raw_metrics = data['metric'].tolist()\n",
    "json_values = data['value'].tolist()\n",
    "json_units = data['unit'].tolist()\n",
    "json_confident = data['confidence'].tolist()\n",
    "\n",
    "# 加载目标标签的CSV文件\n",
    "csv_data = pd.read_excel('../dictionary_new.xlsx')\n",
    "target_labels = csv_data['keyword'].dropna().unique().tolist()\n",
    "\n",
    "# 获取BERT嵌入\n",
    "json_embeddings = get_bert_embeddings_with_progress(raw_metrics, \"Calculating metrics embeddings\")\n",
    "target_embeddings = get_bert_embeddings_with_progress(target_labels, \"Calculating target label embeddings\")\n",
    "\n",
    "# 设置相似度阈值\n",
    "similarity_threshold = 0.7\n",
    "filtered_data = []\n",
    "\n",
    "# 比较每个 metric 和目标标签的相似度，并筛选数据\n",
    "for i, raw_metric in tqdm(enumerate(raw_metrics), desc=\"Calculating similarities\", total=len(raw_metrics)):\n",
    "    similarities = cosine_similarity([json_embeddings[i]], target_embeddings).flatten()\n",
    "    max_similarity_index = similarities.argmax()\n",
    "    max_similarity = similarities[max_similarity_index]\n",
    "    \n",
    "    if max_similarity >= similarity_threshold:\n",
    "        matched_label = target_labels[max_similarity_index]\n",
    "        standard_metric = csv_data.loc[csv_data['keyword'] == matched_label, 'Metric'].iloc[0]\n",
    "        \n",
    "        # 将 metric, value, unit, key_word, standard_metric 和 similarity 添加到筛选后的数据\n",
    "        filtered_entry = {\n",
    "            # 'raw_metric': raw_metric,\n",
    "            'standard_metric': standard_metric,\n",
    "            'value': json_values[i],\n",
    "            'unit': json_units[i],\n",
    "            # 'key_word': matched_label,\n",
    "            'similarity': float(max_similarity),\n",
    "            'confidence': json_confident[i]\n",
    "        }\n",
    "        filtered_data.append(filtered_entry)\n",
    "\n",
    "filtered_data = pd.DataFrame(filtered_data)\n",
    "\n",
    "df_unique = (\n",
    "    filtered_data.sort_values(by=['standard_metric', 'similarity', 'confidence'], ascending=[True, False, False])\n",
    "    .drop_duplicates(subset='standard_metric', keep='first')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../output/qualitative_metrics_keywords.json', 'r', encoding='utf-8') as f:\n",
    "    qualitative_metrics_keywords = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 qualitative_metrics_keywords 是包含要匹配的 metric 的集合或列表\n",
    "qualitative_metrics_keywords = set(qualitative_metrics_keywords)  # 确保是集合类型，提高查找效率\n",
    "\n",
    "# 使用 loc 来修改 df_unique 中符合条件的行\n",
    "df_unique.loc[df_unique['standard_metric'].isin(qualitative_metrics_keywords), 'value'] = 1\n",
    "\n",
    "# 查看结果\n",
    "print(df_unique)\n",
    "\n",
    "# 保存结果为CSV文件\n",
    "df_unique = pd.DataFrame(df_unique)\n",
    "df_unique.to_csv(merge_filter, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Filtering is complete.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
